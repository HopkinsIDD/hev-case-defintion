---
title: "SSD Clinical Algorithm Children"
author: "Aybuke Koyuncu"
date: "2025-04-07"
output: html_document
---

This code is for running the clinical algorithm analyses in children under 14, who are currently being excluded from the main analyses to align with Bangladesh data. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

# Loading packages 
# library(pacman)
library(here)
library(gtsummary)
library(knitr)
library(cowplot)
library(ggridges)
library(bayesplot)
library(icenReg)
library(dplyr)
library(rpart)
library(rpart.plot)
library(SuperLearner)
library(ROCR)
library(ggplot2)
library(dplyr)
library(janitor)
library(tidyr)


dat_ssd_adjusted <- readRDS("~/Desktop/GitRepos/hev_bentiu/scripts/Case_definitions/dat_ssd_adjusted_children.rds")

dat_ssd_adjusted <- dat_ssd_adjusted %>% select(-bleeding, -itch, -convulsion)

# Symptoms only: 30 days post jaundice onset
dat_ssd_symp <- dat_ssd_adjusted %>% select(-id_sex, -age, -days_since_ajs_baseline) 

```

First run the superlearner and get an ROC curve:
```{r loocv}

# Define the full dataset (not just a training subset)
X_full <- dat_ssd_symp %>% select(-infect_bin)  # Predictors
Y_full <- dat_ssd_symp$infect_bin               # Outcome variable

# Store predictions
n <- nrow(X_full)
loocv_preds <- rep(NA, n)

# Loop over each observation
for (i in 1:n) {
  cat("Fitting LOOCV model", i, "of", n, "\n")
  
  # Leave out the i-th observation
  X_train <- X_full[-i, , drop = FALSE]
  Y_train <- Y_full[-i]
  
  X_test <- X_full[i, , drop = FALSE]
  
  # Fit the model on the remaining data
  model_loocv <- SuperLearner(
    Y = Y_train,
    X = X_train,
    family = binomial(),
    SL.library = list("SL.ranger", # random forest
                      "SL.gam", # generalized additive model
                      "SL.xgboost", # extreme gradient boosting
                      "SL.glmnet"))
  
  # Predict on the left-out observation
  pred <- predict(model_loocv, newdata = X_test)$pred
  loocv_preds[i] <- pred
}

library(pROC)

# Calculate AUC and 95% CI
roc_obj <- roc(Y_full, loocv_preds)

# AUC value
auc_value <- auc(roc_obj)

# 95% CI
auc_ci <- ci.auc(roc_obj, method = "bootstrap", boot.n = 2000)

# Print results
cat(sprintf("LOOCV AUC: %.3f (95%% CI: %.3f–%.3f)\n",
            auc_value, auc_ci[1], auc_ci[3]))

# Compute LOOCV AUC
pred_rocr_loocv <- ROCR::prediction(loocv_preds, Y_full)
auc_loocv <- ROCR::performance(pred_rocr_loocv, measure = "auc")@y.values[[1]]
print(paste("LOOCV AUC:", round(auc_loocv, 3)))

# Create ROC curve data
roc_perf_loocv <- ROCR::performance(pred_rocr_loocv, measure = "tpr", x.measure = "fpr")
roc_data_loocv <- data.frame(
  fpr = unlist(roc_perf_loocv@x.values),
  tpr = unlist(roc_perf_loocv@y.values)
)

# Plot 
roc_curve_30_loocv <- ggplot(roc_data_loocv, aes(x = fpr, y = tpr)) +
  geom_line(color = "red", size = 1, alpha=0.8) + 
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") + 
  labs(x = "1 - Specificity",
       y = "Sensitivity") +
  theme_minimal()

```

Now ensemble learner with age, sex, and days since AJS:

```{r loocv_adjusted}

# Define the full dataset (not just a training subset)
X_full_adjusted <- dat_ssd_adjusted %>% select(-infect_bin)  # Predictors
Y_full_adjusted <- dat_ssd_adjusted$infect_bin               # Outcome variable

# Store predictions
n_adjusted <- nrow(X_full_adjusted)
loocv_preds_adjusted <- rep(NA, n_adjusted)

# Loop over each observation
for (i in 1:n_adjusted) {
  cat("Fitting LOOCV model", i, "of", n_adjusted, "\n")
  
  # Leave out the i-th observation
  X_train <- X_full_adjusted[-i, , drop = FALSE]
  Y_train <- Y_full_adjusted[-i]
  
  X_test <- X_full_adjusted[i, , drop = FALSE]
  
  # Fit the model on the remaining data
  model_loocv <- SuperLearner(
    Y = Y_train,
    X = X_train,
    family = binomial(),
    SL.library = list("SL.ranger", # random forest
                      "SL.gam", # generalized additive model
                      "SL.xgboost", # extreme gradient boosting
                      "SL.glmnet"))
  
  # Predict on the left-out observation
  pred <- predict(model_loocv, newdata = X_test)$pred
  loocv_preds_adjusted[i] <- pred
}

# Calculate AUC and 95% CI
roc_obj2 <- roc(Y_full_adjusted, loocv_preds_adjusted)

# AUC value
auc_value2 <- auc(roc_obj2)

# 95% CI
auc_ci2 <- ci.auc(roc_obj2, method = "bootstrap", boot.n = 2000)

# Print results
cat(sprintf("LOOCV AUC: %.3f (95%% CI: %.3f–%.3f)\n",
            auc_value2, auc_ci2[1], auc_ci2[3]))


# Compute LOOCV AUC
pred_rocr_loocv_adjusted  <- ROCR::prediction(loocv_preds_adjusted, Y_full_adjusted)
auc_loocv_adjusted <- ROCR::performance(pred_rocr_loocv_adjusted, measure = "auc")@y.values[[1]]
print(paste("LOOCV AUC:", round(auc_loocv_adjusted, 3)))

# Create ROC curve data
roc_perf_loocv_adjusted <- ROCR::performance(pred_rocr_loocv_adjusted, measure = "tpr", x.measure = "fpr")
roc_data_loocv_adjusted <- data.frame(
  fpr = unlist(roc_perf_loocv_adjusted@x.values),
  tpr = unlist(roc_perf_loocv_adjusted@y.values)
)

# Plot 
roc_curve_30_loocv_adjusted <- ggplot(roc_data_loocv_adjusted, aes(x = fpr, y = tpr)) +
  geom_line(color = "red", size = 1, alpha=0.8) + 
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") + 
  labs(x = "1 - Specificity",
       y = "Sensitivity") +
  theme_minimal()

```

Now put both ROC curves in the same figure

```{r roc}

# Add a model type column to each data frame
roc_data_loocv$model <- "Signs/symptoms"
roc_data_loocv_adjusted$model <- "Signs/symptoms plus demographics"

# Combine both data frames
roc_combined <- rbind(roc_data_loocv, roc_data_loocv_adjusted)

# Plot both ROC curves in one plot with a legend
combined <- ggplot(roc_combined, aes(x = fpr, y = tpr, color = model)) +
  geom_line(size = 1) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "black") +
  scale_color_manual(values = c("Signs/symptoms" = "red",
                                "Signs/symptoms plus demographics" = "darkred")) +
  labs(x = "1 - Specificity",
       y = "Sensitivity",
       color = NULL) +  # Removes the legend title
  theme_minimal() +  theme(legend.position = "bottom") 

combined
```

Evaluate the sens/spec of existing case definitions

```{r case_def}
########################
# MSF case definitions #
########################

dat_ssd_symp <- dat_ssd_symp %>% mutate(msf_def = case_when(
fatigue=="Yes" | epigastric_pain=="Yes" | nausea=="Yes" | loss_appetite=="Yes" ~ 1,
TRUE ~ 0))

# Compare sensitivity to ELISA+
tabyl(dat_ssd_symp, msf_def, infect_bin)

 sens_msf <- 95 / (95+44)
 spec_msf <- 93 / (93+162)

sens_msf_ci <- prop.test(95, 95 + 44, conf.level = 0.95, correct = FALSE)$conf.int
spec_msf_ci <- prop.test(93, 93 + 162, conf.level = 0.95, correct = FALSE)$conf.int
  
sens_msf
sens_msf_ci

spec_msf
spec_msf_ci

########################
# WHO case definitions #
########################

dat_ssd_symp <- dat_ssd_symp %>% mutate(who_def = case_when(
fatigue=="Yes" | fever=="Yes" ~ 1,
TRUE ~ 0))

# Compare sensitivity to ELISA+
tabyl(dat_ssd_symp, who_def, infect_bin)

 sens_who <- 127 / (127 + 12)
 spec_who <- 26 / (26 + 229)

sens_who_ci <- prop.test(127, 127 + 12, conf.level = 0.95, correct = FALSE)$conf.int
spec_who_ci <- prop.test(26, 26 + 229, conf.level = 0.95, correct = FALSE)$conf.int

sens_who
sens_who_ci

spec_who
spec_who_ci

########################
# IMC case definitions #
########################

dat_ssd_symp <- dat_ssd_symp %>% mutate(imc_def = case_when(
fatigue=="Yes" | loss_appetite=="Yes" | fever=="Yes" | abdomen_pain=="Yes" | joint_pains=="Yes"  ~ 1,
TRUE ~ 0))

# Compare sensitivity to ELISA+
tabyl(dat_ssd_symp, imc_def, infect_bin)

sens_imc <- 135 / (135 + 4)
spec_imc <- 10 / (10 + 245)

sens_imc_ci <- prop.test(135, 135 + 4, conf.level = 0.95, correct = FALSE)$conf.int
spec_imc_ci <- prop.test(10, 10 + 245, conf.level = 0.95, correct = FALSE)$conf.int
  
sens_imc
sens_imc_ci

spec_imc
spec_imc_ci

```
